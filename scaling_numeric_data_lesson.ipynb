{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae862288",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "### Numeric Scaling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08e689f",
   "metadata": {},
   "source": [
    "[Course Content](https://ds.codeup.com/regression/split-and-scale/)\n",
    "\n",
    "**Objective:** Transform data to produce values that:\n",
    "\n",
    "- have a desired range\n",
    "- follow a desired distribution\n",
    "\n",
    "\n",
    "**Purpose:** Appropriately scaled data enhances the performance of various machine learning algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31751a17",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "### Why scale data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee5369b",
   "metadata": {},
   "source": [
    "Scaling data addresses issues associated with varying magnitudes across features.\n",
    "\n",
    "Differences in magnitude can affect the performance of the underlying algorithms used to train a model. \n",
    "\n",
    "   - E.g. A single feature dominates and other features are not given influence\n",
    "    \n",
    "\n",
    "If values are of a comparable scale, computation is simplified and the model may have better performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f23f44b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "### Which machine learning algorithms should use scaled features?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7a6e07",
   "metadata": {},
   "source": [
    "Certain ML algorithms either require that data be of comparable scale or perform better when it is.\n",
    "\n",
    "- Distance-based calculations (e.g. KNN or SVM)\n",
    "- Linear and logistic regression \n",
    "- Dimensional reduction (e.g. Principal Components Analysis)\n",
    "- Neural networks\n",
    "\n",
    "Collectively, this is implemented using the `sklearn preprocessing` [package](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec95a65",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "### Terminology \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492eefd4",
   "metadata": {},
   "source": [
    "\n",
    "**Scale**\n",
    "\n",
    "  - Adjusts the range of values\n",
    "  - Preserves distribution of the values\n",
    "\n",
    "**Standardize**\n",
    "\n",
    "  - Adjusts values to have a standard deviation of 1 and mean of 0.\n",
    "   \n",
    "**Normalize**\n",
    "\n",
    "  - Is often used to refer to scaling and standardization\n",
    "  \n",
    "  \n",
    "  - Important: May refer to transforming to the **unit norm** with [normalize.](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html)\n",
    "\n",
    "    - Applied to an entire row of values\n",
    "    - The sum of the squares of the values is equal to 0\n",
    "      \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47446af0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "### Scaling within the Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7ef89f",
   "metadata": {},
   "source": [
    "**Data preparation:**\n",
    "\n",
    "- Transforming data using scaling, standardization, or normalization is conducted during the preparation of the data. \n",
    "\n",
    "\n",
    "- Exploration should be performed with unaltered data. \n",
    "\n",
    "\n",
    "- Statistical tests can generally be performed with unaltered data.\n",
    "\n",
    "\n",
    "- Scaling should be applied post-splitting\n",
    "\n",
    "\n",
    "- Units of measurement should be interpreted with unaltered data.\n",
    "\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- Retain both the altered and unaltered data for use throughout your work. \n",
    "\n",
    "\n",
    "- Create functions which will take data and perform a transformation for use in data preparation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a46100a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "### How are features scaled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db13dc6",
   "metadata": {},
   "source": [
    "Computing and applying various statistics from the data set:\n",
    "    \n",
    "   - minimum\n",
    "   - maximum\n",
    "   - range \n",
    "   - mean\n",
    "   - quantiles\n",
    "   - standard deviation\n",
    "    \n",
    "**Note:** If these values are not known, scaling may not be useful. \n",
    "\n",
    "\n",
    "Features are scaled *independently*. Create and apply a scaler for separate features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc234b9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "### Demonstrating the scaling process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8627ac39",
   "metadata": {},
   "source": [
    "\n",
    "    1. Generate random data with numpy\n",
    "    2. Visualize the data\n",
    "    3. Split the data\n",
    "    4. Apply a scaling function\n",
    "    5. Visualize the transformed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de060b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Libraries \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04010398",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "### Demonstration of MinMax Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d0b165",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. Generate and plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090f3b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = stats.skewnorm(7).rvs(1500) * 10 + 100\n",
    "x = x.reshape(-1, 1)\n",
    "\n",
    "plt.hist(x, bins = 25, ec = 'black')\n",
    "print('Here is a histogram of the dataset we will be working with.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0df4dff",
   "metadata": {},
   "source": [
    "### 2. Split the dataset into train, test, and validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e502a188",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_and_validate, x_test = train_test_split(x, random_state=123)\n",
    "\n",
    "x_train, x_validate = train_test_split(x_train_and_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ced9be",
   "metadata": {},
   "source": [
    "### 3. Create a MinMaxScaler object and apply it to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "080aac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "# Note that we only call .fit with the training data,\n",
    "# but we use .transform to apply the scaling to all the data splits.\n",
    "scaler.fit(x_train)\n",
    "\n",
    "\n",
    "### Apply to train, validate, and test\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_validate_scaled = scaler.transform(x_validate)\n",
    "x_test_scaled = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5279496e",
   "metadata": {},
   "source": [
    "### 4. Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c8066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "plt.subplot(121)\n",
    "plt.hist(x_train, bins=25, ec='black')\n",
    "plt.title('Original')\n",
    "plt.subplot(122)\n",
    "plt.hist(x_train_scaled, bins=25, ec='black')\n",
    "plt.title('Scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580fdb20",
   "metadata": {},
   "source": [
    "### Fitting and transforming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397a25ad",
   "metadata": {},
   "source": [
    "`fit`  Produces the parameters needed to perform the transformation\n",
    "\n",
    "   - Conducted using the training portion of the dataset \n",
    "    \n",
    "`transform` Applies the scaling to the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caeb64f",
   "metadata": {},
   "source": [
    "### Linear versus Non-linear\n",
    "\n",
    "**Linear:** Preserves underlying distribution\n",
    "     \n",
    "\n",
    "**Non-linear:** Alters distribution of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb04492",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "### SciKit Learn Transformation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9896b2",
   "metadata": {},
   "source": [
    "#### `MinMaxScaler`\n",
    "\n",
    "[Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)\n",
    "\n",
    "- Scales features to produce a desired range\n",
    "- Range can be specified in the function \n",
    "\n",
    "\n",
    "\n",
    "$$ x' = \\dfrac{x - min(x)}{max(x) - min(x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5499895a",
   "metadata": {},
   "source": [
    "#### `StandardScaler`\n",
    "\n",
    "[Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "\n",
    "- Scales features to produce a desired distribution \n",
    "- Makes the standard deviation to 1\n",
    "- Centers the values aronud a mean of 0\n",
    "\n",
    "\n",
    "$$x' =  \\dfrac{x - \\bar{x}}{\\sigma_{x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa44d66",
   "metadata": {},
   "source": [
    "#### `RobustScaler`\n",
    "\n",
    "[Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html)\n",
    "\n",
    "- Scales features using the IQR \n",
    "- Reduces impact of outliers\n",
    "\n",
    "$$x' =  \\dfrac{x - med(x)}{IQR_{x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdbdb97",
   "metadata": {},
   "source": [
    "#### `QuantileTransformer`\n",
    "\n",
    "[Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html)\n",
    "- Uses a data set's quantile values \n",
    "- Reduces impact of outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc170e7",
   "metadata": {},
   "source": [
    "### Demonstration of Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27490283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "# Note that we only call .fit with the training data,\n",
    "# but we use .transform to apply the scaling to all the data splits.\n",
    "scaler.fit(x_train)\n",
    "\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_validate_scaled = scaler.transform(x_validate)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.subplot(121)\n",
    "plt.hist(x_train, bins=25, ec='black')\n",
    "plt.title('Original')\n",
    "plt.subplot(122)\n",
    "plt.hist(x_train_scaled, bins=25, ec='black')\n",
    "plt.title('Scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618b33e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97672f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95dc0907",
   "metadata": {},
   "source": [
    "### Demonstration of Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4475a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.RobustScaler()\n",
    "# Note that we only call .fit with the training data,\n",
    "# but we use .transform to apply the scaling to all the data splits.\n",
    "scaler.fit(x_train)\n",
    "\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_validate_scaled = scaler.transform(x_validate)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.subplot(121)\n",
    "plt.hist(x_train, bins=25, ec='black')\n",
    "plt.title('Original')\n",
    "plt.subplot(122)\n",
    "plt.hist(x_train_scaled, bins=25, ec='black')\n",
    "plt.title('Scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ca98d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1184a1a",
   "metadata": {},
   "source": [
    "### Exercise Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a0e448",
   "metadata": {},
   "source": [
    "\n",
    "Notebook: `scaling.ipynb`\n",
    "\n",
    "\n",
    "- Apply various transformations to data you have prepared\n",
    "- Observe the differences in the transformed data\n",
    "- Create preparation functions to transform data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
